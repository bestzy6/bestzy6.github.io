<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://avatars.githubusercontent.com/u/43753176?v=4"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="# 前言

目前，许多开源项目都实现了Agent，如Langchain、LlamaIndex等，使用开源框架的确能够方便我们快速开发出Agent，但代价是开发者对执行流程的不可控。">
<meta property="og:title" content="使用Go语言基于ReAct范式实现LLMAgent">
<meta property="og:description" content="# 前言

目前，许多开源项目都实现了Agent，如Langchain、LlamaIndex等，使用开源框架的确能够方便我们快速开发出Agent，但代价是开发者对执行流程的不可控。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://bestzy6.github.io/post/shi-yong-Go-yu-yan-ji-yu-ReAct-fan-shi-shi-xian-LLMAgent.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/43753176?v=4">
<title>使用Go语言基于ReAct范式实现LLMAgent</title>
<link href="//unpkg.com/@wooorm/starry-night@2.1.1/style/both.css" rel="stylesheet" />


</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
</style>




<body>
    <div id="header">
<h1 class="postTitle">使用Go语言基于ReAct范式实现LLMAgent</h1>
<div class="title-right">
    <a href="https://bestzy6.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/bestzy6/bestzy6.github.io/issues/2" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h1>前言</h1>
<p>目前，许多开源项目都实现了Agent，如Langchain、LlamaIndex等，使用开源框架的确能够方便我们快速开发出Agent，但代价是开发者对执行流程的不可控。</p>
<p>开源框架的Prompt较为固定不易修改，且实现的代码也是与其Prompt高度适配的，但不同LLM的能力相差较大，完全依赖开源框架无法都取得好的效果。</p>
<p>因此，我们可以使用Langchain、LlamaIndex等框架，甚至Dify workflow来快速验证想法，而在生产环境下再自行实现Agent，这样也方便我们根据具体业务进行Prompt以及流程的调整。</p>
<h1>ReAct</h1>
<p>实现Agent的理论基础是ReAct框架。ReAct框架出自论文[<a href="https://arxiv.org/abs/2210.03629" rel="nofollow">《ReAct: Synergizing Reasoning and Acting in Language Models》</a>](<a href="https://arxiv.org/abs/2210.03629)%EF%BC%8C%E5%AE%83%E8%A6%81%E6%B1%82" rel="nofollow">https://arxiv.org/abs/2210.03629)，它要求</a> LLM以交错的方式生成“推理轨迹”和“任务特定操作”，允许 LLM与外部工具交互来获取额外信息，从而给出更可靠和实际的回应。</p>
<p>论文中给出了ReAct的思路，但并没有给出具体的实现方法，本文参照论文思路，给出实现ReAct的Prompt以及流程。</p>
<h1>ReAct Prompt</h1>
<p>Prompt是实现ReAct的核心，以下Prompt参考了LlamaIndex框架。</p>
<pre class="notranslate"><code class="notranslate">## Background
{{ .Background }}

You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.

## Tools

You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.
This may require breaking the task into subtasks and using different tools to complete each subtask.

You have access to the following tools:
{{ .ToolDesc }}

## Output Format

Please answer in the same language as the question and use the following format:

```
Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.
Action: tool name (one of {{ .ToolNames }}) if using a tool.
Action Input: the input to the tool, in a JSON format representing the kwargs ( e.g. {"input": "hello world", "num_beams": 5} )
```

Please ALWAYS start with a Thought.

Please use a valid JSON format for the Action Input.

Then, you need wait for user's respond. If this format is used, the user will respond in the following format.

```
Observation: tool response
```

Otherwise, user will remind you to correct your input in the following format.

```
Error: remind you to correct your input
```

You should keep repeating the above format (JUST include "Thought", "Action" and "Action Input") till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:

```
Thought: I can answer without using any more tools. I'll use the user's language to answer
Answer: [your answer here (In the same language as the user's question)]
```

```
Thought: I cannot answer the question with the provided tools.
Answer: [your answer here (In the same language as the user's question)]
```

## Current Conversation

Below is the current conversation consisting of interleaving human and assistant messages.
</code></pre>
<p>该Prompt首先允许开发者自定义“背景信息”，提供“背景信息”有利于LLM做出更好的选择。然后，Prompt定义了可使用的工具，由开发者自定义，最后，具体描述了工作流程，该流程与论文中的相似。</p>
<p>根据该Prompt，期望的消息形式如下：</p>
<div class="highlight highlight-text-xml"><pre class="notranslate">&lt;<span class="pl-ent">Systemt</span>&gt;
...省略
&lt;/<span class="pl-ent">Systemt</span>&gt;

&lt;<span class="pl-ent">User</span>&gt;
Question: 北京的天气怎么样？
&lt;/<span class="pl-ent">User</span>&gt;

&lt;<span class="pl-ent">Assistant</span>&gt;
Thought: I need to use WeatherTool to help me answer the question.
Action: WeatherTool
Action Input: {"position": "beijing"}
&lt;/<span class="pl-ent">Assistant</span>&gt;

&lt;<span class="pl-ent">User</span>&gt;
Observation: 小雨，天空阴沉。
&lt;/<span class="pl-ent">User</span>&gt;

&lt;<span class="pl-ent">Assistant</span>&gt;
Thought: I can answer without using any more tools. I'll use the user's language to answer
Answer: 今天北京的天气是小雨....
&lt;/<span class="pl-ent">Assistant</span>&gt;</pre></div>
<p>示例展示了LLM的回答格式，我们需要在代码中实现相应的数据解析方法。</p>
<h1>实现流程</h1>
<h2>LLM响应内容获取</h2>
<p>LLM被期望的回答格式仅有两种，即</p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">Thought</span>: <span class="pl-s">I need to use WeatherTool to help me answer the question.</span>
<span class="pl-ent">Action</span>: <span class="pl-s">WeatherTool</span>
<span class="pl-ent">Action Input</span>: <span class="pl-s">{"position": "beijing"}</span></pre></div>
<p>和</p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">Thought</span>: <span class="pl-s">I can answer without using any more tools. I'll use the user's language to answer</span>
<span class="pl-ent">Answer</span>: <span class="pl-s">今天北京的天气是小雨....</span></pre></div>
<p>我们需要按照格式提取相关信息，可借用正则表达式实现信息提取</p>
<ul>
<li>对于第一种的正则表达式如下：</li>
</ul>
<pre class="notranslate"><code class="notranslate">^\s*Thought: (.*?)\n+Action: ([a-zA-Z0-9_]+).*?\n+Action Input: .*?(\{.*\})
</code></pre>
<p>这段正则表达式用于从一段文本中提取三个部分的信息：</p>
<ol>
<li>从开头匹配“Thought: ”后面的内容，直到遇到一个或多个换行符。</li>
<li>匹配“Action: ”后面的Action名称（由字母、数字和下划线组成），直到遇到一个或多个换行符。</li>
<li>匹配“Action Input: ”后面花括号包围的内容。</li>
</ol>
<ul>
<li>第二种对应的正则表达式为：</li>
</ul>
<pre class="notranslate"><code class="notranslate">\s*Thought:(.*?)\n+Answer:.*?(.*)
</code></pre>
<p>这段正则表达式用于从一段文本中提取两个部分的信息：</p>
<ol>
<li>匹配“Thought:”后面的内容，直到遇到一个或多个换行符。</li>
<li>匹配“Answer:”后面的内容，直到字符串结束。</li>
</ol>
<h2>工作逻辑实现</h2>
<p>一旦我们提取LLM的响应信息，我们就可以根据Prompt描述的工作流程实现相应的代码。</p>
<p>将LLM的Action Input交给对应的工具进行处理，并将Observation返回给LLM。当然，LLM可能返回的是Answer。</p>
<p>代码实现即判断输出中是否包含流程特征，如文字中包含Action或Answer。</p>
<div class="highlight highlight-source-go"><pre class="notranslate"><span class="pl-k">switch</span>{
<span class="pl-k">case</span> <span class="pl-s1">strings</span>.<span class="pl-en">Contain</span>(<span class="pl-s1">output</span>,<span class="pl-s">"Action:"</span>):
    <span class="pl-c">// ... 处理函数调用</span>
<span class="pl-k">case</span> <span class="pl-s1">strings</span>.<span class="pl-en">Contain</span>(<span class="pl-s1">output</span>,<span class="pl-s">"Answer:"</span>):
    <span class="pl-c">// ... 处理最终回答</span>
<span class="pl-k">default</span>:
    <span class="pl-c">// ... 出现错误，给LLM反馈信息</span>
}</pre></div>
<h1>常见错误及处理</h1>
<p>大部分厂商都对它们的LLM进行了FunctionCall能力的调整，在大部分情况下都能正确地遵循指令，但并非所有模型都按照理预期进行回答。根据我个人的实践经验，我总结了以下几种错误。</p>
<h2>错误1：调用不存在的工具</h2>
<p>模型有时可能出现幻觉，会调用了不存在的工具，一般的处理的方法有</p>
<ol>
<li>返回错误，中止流程；</li>
<li>选用默认工具来处理；</li>
</ol>
<p>此外，还有一种选择是给LLM反馈信息，告知LLM该工具不存在且只能选择特定的工具等，接着要求LLM重新思考。LLM收到反馈后往往能回至原轨。</p>
<p>如何给模型反馈呢？大家可以注意到在Prompt定义了一种工作流，即</p>
<pre class="notranslate"><code class="notranslate">Error: remind you to correct your input
</code></pre>
<p>那么当发生错误时，我们直接向模型输出错误反馈，此时对话将变为以下形式：</p>
<div class="highlight highlight-text-xml"><pre class="notranslate">&lt;<span class="pl-ent">Systemt</span>&gt;
...省略
&lt;/<span class="pl-ent">Systemt</span>&gt;

&lt;<span class="pl-ent">User</span>&gt;
北京的天气怎么样
&lt;/<span class="pl-ent">User</span>&gt;

&lt;<span class="pl-ent">Assistant</span>&gt;
Thought: I need to use WeatherTool to help me answer the question.
Action: PositionTool
Action Input: {"position": "beijing"}
&lt;/<span class="pl-ent">Assistant</span>&gt;

&lt;<span class="pl-ent">User</span>&gt;
Error: 工具不存在，请选择指定的工具类型，......
&lt;/<span class="pl-ent">User</span>&gt;

&lt;<span class="pl-ent">Assistant</span>&gt;
Thought: Something wrong happened, I need to use WeatherTool to help me answer the question.
Action: WeatherTool
Action Input: {"position": "beijing"}
&lt;/<span class="pl-ent">Assistant</span>&gt;</pre></div>
<h2>错误2：调用工具的入参错误</h2>
<p>这种错误情况的处理方法与错误1相同，可以给LLM反馈以便LLM修正错误。</p>
<h2>错误3：未真正调用工具便得出最终回答</h2>
<p>从名称上看较为抽象，我这里给出这种错误的举例：</p>
<div class="highlight highlight-text-xml"><pre class="notranslate">&lt;<span class="pl-ent">User</span>&gt;
北京的天气怎么样
&lt;/<span class="pl-ent">User</span>&gt;

&lt;<span class="pl-ent">Assistant</span>&gt;
Thought: I need to use WeatherTool to help me answer the question.
Action: WeatherTool
Action Input: {"position": "beijing"}
Observation: 北京是晴天
Thought: xxxxx
Answer: 北京天晴
&lt;/<span class="pl-ent">Assistant</span>&gt;</pre></div>
<p>这种错误情况会直接造成LLM没有进行任何工具调用便给出了最终答案，因为中间工具调用过程的结果均是LLM产生的幻觉。</p>
<p>这种错误可以通过正则表达式与代码的判断逻辑解决。当LLM响应之后，我们先判断响应中夫否存在Action，假如存在则只提取第一个Action以及Action Input，然后自行构造新的消息体，以此屏蔽掉LLM的幻觉。</p>
<h2>错误4：Action Input的参数错误</h2>
<p>一般情况下，LLM的错误往往是大小写、大小驼峰等格式不正确，而并非胡乱输入。</p>
<p>对于这种情况，我们如果能在代码中进行判断，就最好不要给模型以反馈，毕竟每一次反馈都有时间成本。</p>
<p>可以将ActionInput反序列化至map中，然后便利map的键值对，自行修正输入。如：</p>
<div class="highlight highlight-source-go"><pre class="notranslate"><span class="pl-k">var</span> <span class="pl-s1">m</span> <span class="pl-k">map</span>[<span class="pl-smi">string</span>]<span class="pl-k">interface</span>{}
<span class="pl-s1">json</span>.<span class="pl-en">Unmarshal</span>(<span class="pl-s1">data</span>,<span class="pl-c1">&amp;</span><span class="pl-s1">m</span>)</pre></div>
<h1>优秀实践</h1>
<ul>
<li>设计Agent流程时要考虑LLM的常见错误并进行兜底；</li>
<li>给LLM反馈错误让其自行修正；</li>
<li>优先在代码中修正错误，降低调用的时间成本。</li>
</ul>
<h1>总结</h1>
<p>本文介绍了如何使用Go语言实现基于ReAct框架的Agent。ReAct框架通过交错生成“推理轨迹”和“任务特定操作”，允许LLM与外部工具交互，给出更可靠的回应。此外，本文还提供了优秀实践，包括设计Agent流程时考虑LLM常见错误并进行兜底、给LLM反馈错误让其自行修正、优先在代码中修正错误等。</p></div>
<div style="font-size:small;margin-top:8px;float:right;"></div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://bestzy6.github.io">Bestzy's Blog</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","bestzy6/bestzy6.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}
</script>


</html>
